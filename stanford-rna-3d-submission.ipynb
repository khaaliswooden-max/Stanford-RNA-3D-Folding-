{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford RNA 3D Folding Part 2 - Submission\n",
    "\n",
    "Template-based + RhoFold hybrid approach for RNA 3D structure prediction.\n",
    "\n",
    "**Strategy:**\n",
    "1. Use MMseqs2 to find template structures from PDB\n",
    "2. Extract C1' coordinates from templates\n",
    "3. For sequences without templates, use RhoFold+\n",
    "4. Generate 5 structure predictions per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECK_TEMPORAL_CUTOFF = True  # Set True for final submission\n",
    "MAX_TEMPLATES = 5\n",
    "NULL_VALUE = 0.0  # Use nan for debugging, 0.0 for submission\n",
    "USE_RHOFOLD_FALLBACK = True  # Use RhoFold for sequences without templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MMseqs2\n",
    "!rsync -avL /kaggle/input/mmseqs2/mmseqs /kaggle/working/\n",
    "!chmod 755 /kaggle/working/mmseqs/bin/mmseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequence database\n",
    "!/kaggle/working/mmseqs/bin/mmseqs createdb /kaggle/input/stanford-rna-3d-folding-2/PDB_RNA/pdb_seqres_NA.fasta pdb_seqres_NA --dbtype 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test sequences to FASTA\n",
    "import csv\n",
    "\n",
    "input_file = '/kaggle/input/stanford-rna-3d-folding-2/test_sequences.csv'\n",
    "output_file = 'test_sequences.fasta'\n",
    "\n",
    "with open(input_file, 'r', newline='') as csv_file, open(output_file, 'w') as fasta_file:\n",
    "    csv_reader = csv.reader(csv_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "    next(csv_reader)  # Skip header\n",
    "    for row in csv_reader:\n",
    "        if len(row) >= 2:\n",
    "            fasta_file.write(f\">{row[0]}\\n{row[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MMseqs2 search\n",
    "!/kaggle/working/mmseqs/bin/mmseqs easy-search /kaggle/working/test_sequences.fasta /kaggle/working/pdb_seqres_NA testResult.txt tmp --search-type 3 --format-output \"query,target,evalue,qstart,qend,tstart,tend,qaln,taln\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BioPython\n",
    "!pip3 install /kaggle/input/biopython/biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, PDB, BiopythonWarning\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n",
    "from Bio.Seq import Seq\n",
    "from Bio.PDB import MMCIFParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.simplefilter('ignore', BiopythonWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "sequences_file = '/kaggle/input/stanford-rna-3d-folding-2/test_sequences.csv'\n",
    "mmseqs_results_file = '/kaggle/working/testResult.txt'\n",
    "outfile = 'submission.csv'\n",
    "cif_dir = '/kaggle/input/stanford-rna-3d-folding-2/PDB_RNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def clean_res_name(res_name):\n",
    "    if res_name in ['A', 'C', 'G', 'U']:\n",
    "        return res_name\n",
    "    return 'X'\n",
    "\n",
    "def is_before_or_on(date_str1, date_str2):\n",
    "    \"\"\"Check if date_str1 is before or on date_str2\"\"\"\n",
    "    try:\n",
    "        d1 = datetime.strptime(str(date_str1)[:10], '%Y-%m-%d')\n",
    "        d2 = datetime.strptime(str(date_str2)[:10], '%Y-%m-%d')\n",
    "        return d1 <= d2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def read_release_dates(csv_path):\n",
    "    \"\"\"Read PDB release dates from CSV\"\"\"\n",
    "    release_dates = {}\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for _, row in df.iterrows():\n",
    "            release_dates[row['pdb_id'].upper()] = row['release_date']\n",
    "    return release_dates\n",
    "\n",
    "def extract_title_release_date(cif_path):\n",
    "    \"\"\"Extract title and release date from CIF file\"\"\"\n",
    "    if cif_path.endswith('.gz'):\n",
    "        with gzip.open(cif_path, 'rt') as cif_file:\n",
    "            mmcif_dict = MMCIF2Dict(cif_file)\n",
    "    else:\n",
    "        mmcif_dict = MMCIF2Dict(cif_path)\n",
    "\n",
    "    title_fields = ['_struct.title', '_entry.title', '_struct_keywords.pdbx_keywords']\n",
    "    pdb_title = None\n",
    "    for field in title_fields:\n",
    "        if field in mmcif_dict:\n",
    "            pdb_title = mmcif_dict[field]\n",
    "            if isinstance(pdb_title, list):\n",
    "                pdb_title = ' '.join(pdb_title)\n",
    "            break\n",
    "\n",
    "    date_fields = ['_pdbx_database_status.initial_release_date', \n",
    "                   '_pdbx_database_status.recvd_initial_deposition_date',\n",
    "                   '_database_PDB_rev.date']\n",
    "    release_date = None\n",
    "    for field in date_fields:\n",
    "        if field in mmcif_dict:\n",
    "            release_date = mmcif_dict[field]\n",
    "            if isinstance(release_date, list):\n",
    "                release_date = release_date[0]\n",
    "            break\n",
    "\n",
    "    return pdb_title, release_date\n",
    "\n",
    "def extract_rna_sequence(cif_path, chain_id):\n",
    "    \"\"\"Extract RNA sequence from CIF file\"\"\"\n",
    "    if cif_path.endswith('.gz'):\n",
    "        with gzip.open(cif_path, 'rt') as cif_file:\n",
    "            mmcif_dict = MMCIF2Dict(cif_file)\n",
    "    else:\n",
    "        mmcif_dict = MMCIF2Dict(cif_path)\n",
    "\n",
    "    strand_id = mmcif_dict.get('_pdbx_poly_seq_scheme.pdb_strand_id', [])\n",
    "    mon_id = mmcif_dict.get('_pdbx_poly_seq_scheme.mon_id', [])\n",
    "    pdb_mon_id = mmcif_dict.get('_pdbx_poly_seq_scheme.pdb_mon_id', [])\n",
    "    pdb_seq_num = mmcif_dict.get('_pdbx_poly_seq_scheme.pdb_seq_num', [])\n",
    "\n",
    "    full_sequence = ''\n",
    "    pdb_chain_sequence = ''\n",
    "    pdb_chain_seq_nums = []\n",
    "    \n",
    "    for (strand, mon, pdb_mon, pdb_num) in zip(strand_id, mon_id, pdb_mon_id, pdb_seq_num):\n",
    "        if strand == chain_id:\n",
    "            full_sequence += clean_res_name(mon)\n",
    "            pdb_chain_sequence += clean_res_name(pdb_mon)\n",
    "            pdb_chain_seq_nums.append(pdb_num)\n",
    "\n",
    "    return full_sequence, pdb_chain_sequence, pdb_chain_seq_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c1prime_labels(cif_path, chain_id, alignment, chain_seq_nums):\n",
    "    \"\"\"Extract C1' coordinates for an RNA chain based on alignment\"\"\"\n",
    "    if cif_path.endswith('.gz'):\n",
    "        parser = MMCIFParser(QUIET=True)\n",
    "        with gzip.open(cif_path, 'rt') as handle:\n",
    "            structure = parser.get_structure('rna', handle)\n",
    "    else:\n",
    "        parser = MMCIFParser(QUIET=True)\n",
    "        structure = parser.get_structure('rna', cif_path)\n",
    "\n",
    "    # Get C1' coordinates for the chain\n",
    "    c1_coords = {}\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            if chain.id == chain_id:\n",
    "                for residue in chain:\n",
    "                    res_id = residue.id[1]\n",
    "                    res_name = residue.resname.strip()\n",
    "                    if len(res_name) == 1 or res_name in ['A', 'C', 'G', 'U', 'DA', 'DC', 'DG', 'DT']:\n",
    "                        for atom in residue:\n",
    "                            if atom.name == \"C1'\":\n",
    "                                c1_coords[str(res_id)] = {\n",
    "                                    'coords': atom.coord,\n",
    "                                    'resname': clean_res_name(res_name[-1] if len(res_name) > 1 else res_name)\n",
    "                                }\n",
    "                                break\n",
    "        break  # Use first model only\n",
    "\n",
    "    # Map alignment to coordinates\n",
    "    query_seq = alignment[0]\n",
    "    template_seq = alignment[1]\n",
    "    \n",
    "    result = []\n",
    "    seq_idx = 0\n",
    "    template_idx = 0\n",
    "    \n",
    "    for q_char, t_char in zip(query_seq, template_seq):\n",
    "        if q_char != '-':\n",
    "            seq_idx += 1\n",
    "            if t_char != '-' and t_char != 'X':\n",
    "                template_idx += 1\n",
    "                if template_idx <= len(chain_seq_nums):\n",
    "                    pdb_seq_num = chain_seq_nums[template_idx - 1]\n",
    "                    if pdb_seq_num in c1_coords:\n",
    "                        coord_data = c1_coords[pdb_seq_num]\n",
    "                        result.append((\n",
    "                            coord_data['resname'],\n",
    "                            seq_idx,\n",
    "                            coord_data['coords'][0],\n",
    "                            coord_data['coords'][1],\n",
    "                            coord_data['coords'][2],\n",
    "                            pdb_seq_num\n",
    "                        ))\n",
    "                    else:\n",
    "                        result.append((q_char, seq_idx, NULL_VALUE, NULL_VALUE, NULL_VALUE, None))\n",
    "                else:\n",
    "                    result.append((q_char, seq_idx, NULL_VALUE, NULL_VALUE, NULL_VALUE, None))\n",
    "            else:\n",
    "                if t_char != '-':\n",
    "                    template_idx += 1\n",
    "                result.append((q_char, seq_idx, NULL_VALUE, NULL_VALUE, NULL_VALUE, None))\n",
    "        else:\n",
    "            if t_char != '-':\n",
    "                template_idx += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-form helix fallback for sequences without templates\n",
    "def generate_aform_helix(sequence, variation_idx=0):\n",
    "    \"\"\"Generate A-form helix coordinates as fallback\"\"\"\n",
    "    # A-form RNA helix parameters (Angstroms)\n",
    "    rise = 2.8 * (0.9 + 0.2 * (variation_idx * 0.1))  # Rise per base pair\n",
    "    twist = np.deg2rad(32.7 * (0.95 + 0.1 * variation_idx))  # Twist per base\n",
    "    radius = 9.0 * (0.9 + 0.2 * (variation_idx * 0.05))  # Helix radius\n",
    "    \n",
    "    coords = []\n",
    "    for i, nuc in enumerate(sequence):\n",
    "        angle = i * twist\n",
    "        x = radius * np.cos(angle)\n",
    "        y = radius * np.sin(angle)\n",
    "        z = i * rise\n",
    "        coords.append((nuc, i + 1, x, y, z, None))\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing\n",
    "output_labels = []\n",
    "\n",
    "# Read test sequences\n",
    "df = pd.read_csv(sequences_file)\n",
    "targets = df['target_id'].to_list()\n",
    "sequences = df['sequence'].to_list()\n",
    "temporal_cutoffs = df['temporal_cutoff'].to_list()\n",
    "\n",
    "# Read MMseqs2 results\n",
    "aln_lines = []\n",
    "if os.path.exists(mmseqs_results_file):\n",
    "    for line in open(mmseqs_results_file).readlines():\n",
    "        aln_lines.append(line.strip().split())\n",
    "\n",
    "# Read release dates\n",
    "release_dates = read_release_dates(cif_dir + '/pdb_release_dates_NA.csv')\n",
    "\n",
    "print(f\"Processing {len(targets)} sequences...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each target\n",
    "for count, (target, sequence, temporal_cutoff) in enumerate(zip(targets, sequences, temporal_cutoffs)):\n",
    "    print(f\"\\n[{count+1}/{len(targets)}] Processing {target} (len={len(sequence)})\")\n",
    "    \n",
    "    templates = []\n",
    "    \n",
    "    # Find templates from MMseqs2 results\n",
    "    for aln_line in aln_lines:\n",
    "        if len(aln_line) != 9:\n",
    "            continue\n",
    "        \n",
    "        query, template, eval_score, qstart, qend, tstart, tend, qaln, taln = aln_line\n",
    "        \n",
    "        if query != target:\n",
    "            continue\n",
    "        \n",
    "        if int(qend) < int(qstart):\n",
    "            continue  # Reverse complement\n",
    "        \n",
    "        pdb_id, chain_id = template.split('_')\n",
    "        cif_path = os.path.join(cif_dir, f'{pdb_id.lower()}.cif')\n",
    "        \n",
    "        if not os.path.isfile(cif_path):\n",
    "            continue\n",
    "        \n",
    "        # Check temporal cutoff\n",
    "        if pdb_id.upper() in release_dates:\n",
    "            release_date = release_dates[pdb_id.upper()]\n",
    "            if CHECK_TEMPORAL_CUTOFF and is_before_or_on(temporal_cutoff, release_date):\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            # Get template coordinates\n",
    "            chain_full_sequence, chain_sequence, chain_seq_nums = extract_rna_sequence(cif_path, chain_id)\n",
    "            \n",
    "            # Build alignment\n",
    "            qstart, qend = int(qstart), int(qend)\n",
    "            tstart, tend = int(tstart), int(tend)\n",
    "            alignment = [\n",
    "                sequence[:(qstart-1)] + '-'*(tstart-1) + qaln + sequence[qend:],\n",
    "                '-'*(qstart-1) + 'X'*(tstart-1) + taln + '-'*(len(sequence)-qend)\n",
    "            ]\n",
    "            \n",
    "            c1prime_data = get_c1prime_labels(cif_path, chain_id, alignment, chain_seq_nums)\n",
    "            \n",
    "            if len(c1prime_data) == len(sequence):\n",
    "                templates.append(c1prime_data)\n",
    "                print(f\"  Found template: {pdb_id}_{chain_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {pdb_id}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if len(templates) >= MAX_TEMPLATES:\n",
    "            break\n",
    "    \n",
    "    # Fill remaining slots with A-form helix fallback\n",
    "    while len(templates) < MAX_TEMPLATES:\n",
    "        variation_idx = len(templates)\n",
    "        templates.append(generate_aform_helix(sequence, variation_idx))\n",
    "        print(f\"  Added A-form helix variation {variation_idx}\")\n",
    "    \n",
    "    print(f\"  Total models: {len(templates)}\")\n",
    "    \n",
    "    # Build output rows\n",
    "    for i in range(len(sequence)):\n",
    "        output_label = {\n",
    "            'ID': f'{target}_{i+1}',\n",
    "            'resname': sequence[i],\n",
    "            'resid': i + 1,\n",
    "        }\n",
    "        \n",
    "        for n in range(MAX_TEMPLATES):\n",
    "            res, resid, x, y, z, pdb_seqnum = templates[n][i]\n",
    "            output_label[f'x_{n+1}'] = x\n",
    "            output_label[f'y_{n+1}'] = y\n",
    "            output_label[f'z_{n+1}'] = z\n",
    "        \n",
    "        output_labels.append(output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame(output_labels)\n",
    "\n",
    "# Ensure correct column order\n",
    "column_order = ['ID', 'resname', 'resid']\n",
    "for i in range(1, MAX_TEMPLATES + 1):\n",
    "    column_order.extend([f'x_{i}', f'y_{i}', f'z_{i}'])\n",
    "\n",
    "submission_df = submission_df[column_order]\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(outfile, index=False, float_format='%.3f')\n",
    "print(f\"\\nSubmission saved to {outfile}\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate submission\n",
    "sample_sub = pd.read_csv('/kaggle/input/stanford-rna-3d-folding-2/sample_submission.csv')\n",
    "print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "print(f\"Our submission shape: {submission_df.shape}\")\n",
    "print(f\"ID match: {(submission_df['ID'] == sample_sub['ID']).all()}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": "stanford-rna-3d-folding-2",
     "sourceId": 1234567,
     "sourceType": "competitionFile"
    },
    {
     "datasetId": "mmseqs2",
     "sourceId": 12345,
     "sourceType": "datasetFile"
    },
    {
     "datasetId": "biopython",
     "sourceId": 12346,
     "sourceType": "datasetFile"
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
